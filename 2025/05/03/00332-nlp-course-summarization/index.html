<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="00332 NLP Course - Summarization, NLP LLM DeepLearning LuYF-Lemon-love 自然语言处理 深度学习 大语言模型">
    <meta name="description" content="前言在这一部分，我们将探讨如何使用Transformer模型将长文档浓缩成摘要，这一任务被称为文本摘要。这是自然语言处理中最具挑战性的任务之一，因为它需要多种能力，如理解长篇文章并生成连贯的文本，抓住文档中的主要主题。然而，当做得好时，文本">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>00332 NLP Course - Summarization | LuYF-Lemon-love の Blog</title>
    <link rel="icon" type="image/jpeg" href="https://cos.luyf-lemon-love.space/images/苏苏1.jpeg">
    
    <style>
        body{
            background-image: url(https://cos.luyf-lemon-love.space/images/016-%E6%8A%A5%E7%BA%B8%E5%A2%99%E9%BA%BB%E8%A1%A3%E5%AD%A6%E5%A7%90.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    
        <link rel="stylesheet" type="text/css" href="/css/reward.css">
    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <span class="logo-span">LuYF-Lemon-love の Blog</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="" class="waves-effect waves-light">

      
      <i class="fas fa-list" style="zoom: 0.6;"></i>
      
      <span>List</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="/galleries">
          
          <i class="fas fa-image" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Image</span>
        </a>
      </li>
      
      <li>
        <a href="/verse">
          
          <i class="fas fa-comments" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Verse</span>
        </a>
      </li>
      
      <li>
        <a href="/bilibili">
          
          <i class="fas fa-video" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Bilibili</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <div class="logo-name">LuYF-Lemon-love の Blog</div>
        <div class="logo-desc">
            
            天之道，损有余而补不足，人之道则不然，损不足以奉有余。
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			友情链接
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-list"></i>
			
			List
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>

                  <a href="/galleries " style="margin-left:75px">
				  
				   <i class="fa fas fa-image" style="position: absolute;left:50px" ></i>
			      
		          <span>Image</span>
                  </a>
                </li>
              
                <li>

                  <a href="/verse " style="margin-left:75px">
				  
				   <i class="fa fas fa-comments" style="position: absolute;left:50px" ></i>
			      
		          <span>Verse</span>
                  </a>
                </li>
              
                <li>

                  <a href="/bilibili " style="margin-left:75px">
				  
				   <i class="fa fas fa-video" style="position: absolute;left:50px" ></i>
			      
		          <span>Bilibili</span>
                  </a>
                </li>
              
            </ul>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/yanfeng98/paper-is-all-you-need" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/yanfeng98/paper-is-all-you-need" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    
<script src="/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('请输入访问本文章的密码')).toString(CryptoJS.enc.Hex)) {
                alert('密码错误，将返回主页！');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('https://cos.luyf-lemon-love.space/images/032-meinv.webp')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">00332 NLP Course - Summarization</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                                <span class="chip bg-color">深度学习</span>
                            </a>
                        
                            <a href="/tags/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/">
                                <span class="chip bg-color">大语言模型</span>
                            </a>
                        
                            <a href="/tags/huggingface/">
                                <span class="chip bg-color">huggingface</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" class="post-category">
                                大语言模型
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-05-03
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-05
                </div>
                

                

                

                
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.min.css">
        

        
        <!-- 代码块折行 -->
        <style type="text/css">
            code[class*="language-"], pre[class*="language-"] { white-space: pre-wrap !important; }
        </style>
        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在这一部分，我们将探讨如何使用Transformer模型将长文档浓缩成摘要，这一任务被称为文本摘要。这是自然语言处理中最具挑战性的任务之一，因为它需要多种能力，如理解长篇文章并生成连贯的文本，抓住文档中的主要主题。然而，当做得好时，文本摘要是一个强大的工具，可以通过减轻领域专家的负担，让他们不必详细阅读长文档，从而加快各种业务流程。</p>
<p>尽管Hugging Face Hub上已经存在各种经过微调的摘要模型，但几乎所有这些模型都只适用于英语文档。因此，为了在这个部分增加一些新意，我们将训练一个英语和西班牙语的双语模型。到本部分结束时，你将拥有一个可以总结客户评论的模型，就像这里展示的那样：</p>
<p><img src="https://cos.luyf-lemon-love.space/images/20250503205043.png"></p>
<p><img src="https://cos.luyf-lemon-love.space/images/20250503205149.png"></p>
<p>我们将看到，这些摘要之所以简洁，是因为它们是从客户在产品评论中提供的标题中学到的。让我们首先为这项任务收集一个合适的双语语料库。</p>
<p>src link: <a href="https://huggingface.co/learn/llm-course/chapter7/5">https://huggingface.co/learn/llm-course/chapter7/5</a></p>
<p>Operating System: Ubuntu 22.04.4 LTS</p>
<h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><ol>
<li><a href="https://huggingface.co/learn/llm-course/chapter7/5">NLP Course - Summarization</a></li>
</ol>
<h2 id="准备多语言语料库"><a href="#准备多语言语料库" class="headerlink" title="准备多语言语料库"></a>准备多语言语料库</h2><p>我们将使用<a href="https://huggingface.co/datasets/amazon_reviews_multi">多语言亚马逊评论语料库</a>来创建我们的双语摘要器。这个语料库包含六种语言的亚马逊产品评论，通常用于多语言分类器的基准测试。然而，由于每条评论都附有一个简短的标题，我们可以将这些标题作为我们模型要学习的目标摘要！要开始使用，让我们从Hugging Face Hub下载英语和西班牙语的子集：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset

spanish_dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"amazon_reviews_multi"</span><span class="token punctuation">,</span> <span class="token string">"es"</span><span class="token punctuation">)</span>
english_dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"amazon_reviews_multi"</span><span class="token punctuation">,</span> <span class="token string">"en"</span><span class="token punctuation">)</span>
english_dataset<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">DatasetDict<span class="token punctuation">(</span><span class="token punctuation">&#123;</span>
    train: Dataset<span class="token punctuation">(</span><span class="token punctuation">&#123;</span>
        features: <span class="token punctuation">[</span><span class="token string">'review_id'</span>, <span class="token string">'product_id'</span>, <span class="token string">'reviewer_id'</span>, <span class="token string">'stars'</span>, <span class="token string">'review_body'</span>, <span class="token string">'review_title'</span>, <span class="token string">'language'</span>, <span class="token string">'product_category'</span><span class="token punctuation">]</span>,
        num_rows: <span class="token number">200000</span>
    <span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
    validation: Dataset<span class="token punctuation">(</span><span class="token punctuation">&#123;</span>
        features: <span class="token punctuation">[</span><span class="token string">'review_id'</span>, <span class="token string">'product_id'</span>, <span class="token string">'reviewer_id'</span>, <span class="token string">'stars'</span>, <span class="token string">'review_body'</span>, <span class="token string">'review_title'</span>, <span class="token string">'language'</span>, <span class="token string">'product_category'</span><span class="token punctuation">]</span>,
        num_rows: <span class="token number">5000</span>
    <span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
    test: Dataset<span class="token punctuation">(</span><span class="token punctuation">&#123;</span>
        features: <span class="token punctuation">[</span><span class="token string">'review_id'</span>, <span class="token string">'product_id'</span>, <span class="token string">'reviewer_id'</span>, <span class="token string">'stars'</span>, <span class="token string">'review_body'</span>, <span class="token string">'review_title'</span>, <span class="token string">'language'</span>, <span class="token string">'product_category'</span><span class="token punctuation">]</span>,
        num_rows: <span class="token number">5000</span>
    <span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
<span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>如你所见，对于每种语言，训练集有200,000条评论，验证集和测试集各有5,000条评论。我们感兴趣的评论信息包含在review_body和review_title列中。让我们通过创建一个简单的函数来查看一些示例，该函数从训练集中随机抽取样本，使用我们在第5章中学到的技术：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">show_samples</span><span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> num_samples<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> seed<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    sample <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>seed<span class="token operator">=</span>seed<span class="token punctuation">)</span><span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>num_samples<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> example <span class="token keyword">in</span> sample<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"\n'>> Title: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>example<span class="token punctuation">[</span><span class="token string">'review_title'</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></span><span class="token string">'"</span></span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"'>> Review: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>example<span class="token punctuation">[</span><span class="token string">'review_body'</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></span><span class="token string">'"</span></span><span class="token punctuation">)</span>


show_samples<span class="token punctuation">(</span>english_dataset<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token string">'>> Title: Worked in front position, not rear'</span>
<span class="token string">'>> Review: 3 stars because these are not rear brakes as stated in the item description. At least the mount adapter only worked on the front fork of the bike that I got it for.'</span>

<span class="token string">'>> Title: meh'</span>
<span class="token string">'>> Review: Does it’s job and it’s gorgeous but mine is falling apart, I had to basically put it together again with hot glue'</span>

<span class="token string">'>> Title: Can\'</span>t beat these <span class="token keyword">for</span> the money<span class="token string">'
'</span><span class="token operator">>></span> Review: Bought this <span class="token keyword">for</span> handling miscellaneous aircraft parts and hanger <span class="token string">"stuff"</span> that I needed to organize<span class="token punctuation">;</span> it really fit the bill. The unit arrived quickly, was well packaged and arrived intact <span class="token punctuation">(</span>always a good sign<span class="token punctuation">)</span>. There are five wall mounts-- three on the <span class="token function">top</span> and two on the bottom. I wanted to <span class="token function">mount</span> it on the wall, so all I had to <span class="token keyword">do</span> was to remove the <span class="token function">top</span> two layers of plastic drawers, as well as the bottom corner drawers, place it when I wanted and mark it<span class="token punctuation">;</span> I <span class="token keyword">then</span> used some of the new plastic screw <span class="token keyword">in</span> wall anchors <span class="token punctuation">(</span>the <span class="token number">50</span> pound variety<span class="token punctuation">)</span> and it easily mounted to the wall. Some have remarked that they wanted dividers <span class="token keyword">for</span> the drawers, and that they made those. Good idea. My application was that I needed something that I can see the contents at about eye level, so I wanted the fuller-sized drawers. I also like that these are the new plastic that doesn<span class="token punctuation">\</span>'t get brittle and <span class="token function">split</span> like my older plastic drawers did. I like the all-plastic construction. It<span class="token punctuation">\</span>'s heavy duty enough to hold metal parts, but being made of plastic it<span class="token punctuation">\</span>'s not as heavy as a metal frame, so you can easily <span class="token function">mount</span> it to the wall and still load it up with heavy stuff, or light stuff. No problem there. For the money, you can<span class="token punctuation">\</span>'t beat it. Best one of these I<span class="token punctuation">\</span>'ve bought to date-- and I<span class="token punctuation">\</span>'ve been using some version of these <span class="token keyword">for</span> over forty years.'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>✏️ 试试看！在 Dataset.shuffle() 命令中更改随机种子，以探索语料库中的其他评论。如果你是西班牙语使用者，不妨看看 spanish_dataset 中的评论，看看标题是否也像是合理的摘要。</p>
</blockquote>
<p>这个样本展示了网上常见的评论的多样性，从正面到负面（以及介于两者之间的各种评论！）。虽然“meh”标题的示例不太有用，但其他标题看起来像是对评论本身的不错的概括。在单个GPU上训练所有40万条评论的摘要模型需要花费太长时间，因此我们将专注于生成单个产品领域的摘要。为了了解我们可以选择哪些领域，让我们将english_dataset转换为pandas.DataFrame并计算每个产品类别的评论数量：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">english_dataset<span class="token punctuation">.</span>set_format<span class="token punctuation">(</span><span class="token string">"pandas"</span><span class="token punctuation">)</span>
english_df <span class="token operator">=</span> english_dataset<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
<span class="token comment"># Show counts for top 20 products</span>
english_df<span class="token punctuation">[</span><span class="token string">"product_category"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>value_counts<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">20</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">home                      <span class="token number">17679</span>
apparel                   <span class="token number">15951</span>
wireless                  <span class="token number">15717</span>
other                     <span class="token number">13418</span>
beauty                    <span class="token number">12091</span>
drugstore                 <span class="token number">11730</span>
kitchen                   <span class="token number">10382</span>
toy                        <span class="token number">8745</span>
sports                     <span class="token number">8277</span>
automotive                 <span class="token number">7506</span>
lawn_and_garden            <span class="token number">7327</span>
home_improvement           <span class="token number">7136</span>
pet_products               <span class="token number">7082</span>
digital_ebook_purchase     <span class="token number">6749</span>
pc                         <span class="token number">6401</span>
electronics                <span class="token number">6186</span>
office_product             <span class="token number">5521</span>
shoes                      <span class="token number">5197</span>
grocery                    <span class="token number">4730</span>
book                       <span class="token number">3756</span>
Name: product_category, dtype: int64<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>英语数据集中最受欢迎的产品是家居用品、服装和无线电子产品。不过，为了紧扣亚马逊的主题，让我们专注于总结书评——毕竟，这才是该公司成立的初衷！我们可以看到两个符合条件的产品类别（书籍和数字电子书购买），所以让我们过滤这两种语言的数据集，只保留这些产品。正如我们在第5章中看到的，Dataset.filter()函数允许我们非常高效地对数据集进行切片，所以我们可以定义一个简单的函数来完成这个任务：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">filter_books</span><span class="token punctuation">(</span>example<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span>
        example<span class="token punctuation">[</span><span class="token string">"product_category"</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">"book"</span>
        <span class="token keyword">or</span> example<span class="token punctuation">[</span><span class="token string">"product_category"</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">"digital_ebook_purchase"</span>
    <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>现在，当我们将这个函数应用到 english_dataset 和 spanish_dataset 时，结果将只包含那些涉及图书类别的行。在应用过滤器之前，让我们将 english_dataset 的格式从 “pandas” 改回 “arrow”：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">english_dataset<span class="token punctuation">.</span>reset_format<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>然后我们可以应用过滤器功能，作为一个安全检查，让我们检查一下评论的样本，看看它们是否确实是关于书籍的：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">spanish_books <span class="token operator">=</span> spanish_dataset<span class="token punctuation">.</span><span class="token builtin">filter</span><span class="token punctuation">(</span>filter_books<span class="token punctuation">)</span>
english_books <span class="token operator">=</span> english_dataset<span class="token punctuation">.</span><span class="token builtin">filter</span><span class="token punctuation">(</span>filter_books<span class="token punctuation">)</span>
show_samples<span class="token punctuation">(</span>english_books<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token string">'>> Title: I\'</span>m dissapointed.<span class="token string">'
'</span><span class="token operator">>></span> Review: I guess I had higher expectations <span class="token keyword">for</span> this book from the reviews. I really thought I<span class="token punctuation">\</span>'d at least like it. The plot idea was great. I loved Ash but, it just didnt go anywhere. Most of the book was about their radio show and talking to callers. I wanted the author to <span class="token function">dig</span> deeper so we could really get to know the characters. All we know about Grace is that she is attractive looking, Latino and is kind of a brat. I<span class="token punctuation">\</span>'m dissapointed.<span class="token string">'

'</span><span class="token operator">>></span> Title: Good art, good price, poor design<span class="token string">'
'</span><span class="token operator">>></span> Review: I had gotten the DC Vintage calendar the past two years, but it was on backorder forever this year and I saw they had shrunk the dimensions <span class="token keyword">for</span> no good reason. This one has good art choices but the design has the <span class="token function">fold</span> going through the picture, so it<span class="token punctuation">\</span>'s <span class="token function">less</span> aesthetically pleasing, especially <span class="token keyword">if</span> you want to keep a picture to hang. For the price, a good calendar<span class="token string">'

'</span><span class="token operator">>></span> Title: Helpful<span class="token string">'
'</span><span class="token operator">>></span> Review: Nearly all the tips useful and. I consider myself an intermediate to advanced user of OneNote. I would highly recommend.'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>好的，我们可以看到这些评论并非严格关于书籍，可能涉及日历和 OneNote 等电子应用程序。尽管如此，这个领域似乎适合训练一个摘要模型。在我们查看适合这项任务的各种模型之前，我们还需要做最后一点数据准备：将英语和西班牙语的评论合并为一个单一的 DatasetDict 对象。🤗 Datasets 提供了一个方便的 concatenate_datasets() 函数，顾名思义，它将两个 Dataset 对象堆叠在一起。因此，为了创建我们的双语数据集，我们将遍历每个分割，拼接该分割的数据集，并对结果进行洗牌，以确保我们的模型不会过度适应单一语言：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> concatenate_datasets<span class="token punctuation">,</span> DatasetDict

books_dataset <span class="token operator">=</span> DatasetDict<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> split <span class="token keyword">in</span> english_books<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    books_dataset<span class="token punctuation">[</span>split<span class="token punctuation">]</span> <span class="token operator">=</span> concatenate_datasets<span class="token punctuation">(</span>
        <span class="token punctuation">[</span>english_books<span class="token punctuation">[</span>split<span class="token punctuation">]</span><span class="token punctuation">,</span> spanish_books<span class="token punctuation">[</span>split<span class="token punctuation">]</span><span class="token punctuation">]</span>
    <span class="token punctuation">)</span>
    books_dataset<span class="token punctuation">[</span>split<span class="token punctuation">]</span> <span class="token operator">=</span> books_dataset<span class="token punctuation">[</span>split<span class="token punctuation">]</span><span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span>

<span class="token comment"># Peek at a few examples</span>
show_samples<span class="token punctuation">(</span>books_dataset<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token string">'>> Title: Easy to follow!!!!'</span>
<span class="token string">'>> Review: I loved The dash diet weight loss Solution. Never hungry. I would recommend this diet. Also the menus are well rounded. Try it. Has lots of the information need thanks.'</span>

<span class="token string">'>> Title: PARCIALMENTE DAÑADO'</span>
<span class="token string">'>> Review: Me llegó el día que tocaba, junto a otros libros que pedí, pero la caja llegó en mal estado lo cual dañó las esquinas de los libros porque venían sin protección (forro).'</span>

<span class="token string">'>> Title: no lo he podido descargar'</span>
<span class="token string">'>> Review: igual que el anterior'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>这看起来确实是英语和西班牙语评论的混合！现在我们有了训练语料库，最后要检查的是评论及其标题中词语的分布情况。这对于摘要任务尤为重要，因为数据中的短参考摘要可能会使模型在生成的摘要中只输出一两个词。下面的图表显示了词语分布情况，我们可以看到标题明显倾向于只使用1-2个词：</p>
<p><img src="https://cos.luyf-lemon-love.space/images/20250504015720.png"></p>
<p>为了解决这个问题，我们将过滤掉那些标题非常短的示例，以便我们的模型能够生成更有趣的摘要。由于我们处理的是英语和西班牙语文本，我们可以使用一个粗略的启发式方法在空格处拆分标题，然后使用我们可靠的Dataset.filter()方法，如下所示：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">books_dataset <span class="token operator">=</span> books_dataset<span class="token punctuation">.</span><span class="token builtin">filter</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> <span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token string">"review_title"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">2</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>现在我们已经准备好了我们的语料库，让我们来看看一些可能在上面进行微调的Transformer模型吧！</p>
<h2 id="文本摘要的模型"><a href="#文本摘要的模型" class="headerlink" title="文本摘要的模型"></a>文本摘要的模型</h2><p>如果你仔细想想，文本摘要的任务与机器翻译类似：我们有一段文本，比如一篇评论，我们希望将其“翻译”成一个更简短的版本，抓住输入的要点。因此，大多数用于摘要的Transformer模型采用了我们在第一章中首次遇到的编码器-解码器架构，尽管也有一些例外，比如GPT系列模型也可以用于少样本设置的摘要。下表列出了一些常用的预训练模型，可以进行摘要微调。</p>
<table>
<thead>
<tr>
<th align="center">Transformer model</th>
<th align="center">Description</th>
<th align="center">Multilingual?</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><a href="https://huggingface.co/gpt2-xl">GPT-2</a></td>
<td align="center">尽管 GPT-2 是作为一个自回归语言模型训练的，但你可以通过在输入文本末尾添加“TL;DR”来让它生成摘要。</td>
<td align="center">❌</td>
</tr>
<tr>
<td align="center"><a href="https://huggingface.co/google/pegasus-large">PEGASUS</a></td>
<td align="center">使用预训练目标来预测多句文本中的掩码句子。这个预训练目标比传统的语言建模更接近于摘要，在流行的基准测试中表现出色。</td>
<td align="center">❌</td>
</tr>
<tr>
<td align="center"><a href="https://huggingface.co/t5-base">T5</a></td>
<td align="center">一种通用的Transformer架构，在文本到文本的框架中表述所有任务；例如，模型对文档进行摘要的输入格式是summarize: ARTICLE。</td>
<td align="center">❌</td>
</tr>
<tr>
<td align="center"><a href="https://huggingface.co/google/mt5-base">mT5</a></td>
<td align="center">基于多语言 Common Crawl 语料库（mC4）预训练的多语言版本 T5，涵盖 101 种语言。</td>
<td align="center">✅</td>
</tr>
<tr>
<td align="center"><a href="https://huggingface.co/facebook/bart-base">BART</a></td>
<td align="center">一种新型Transformer架构，既有编码器又有解码器堆栈，经过训练后可以重建受损的输入，同时结合了BERT和GPT-2的预训练方案。</td>
<td align="center">❌</td>
</tr>
<tr>
<td align="center"><a href="https://huggingface.co/facebook/mbart-large-50">mBART-50</a></td>
<td align="center">BART的多语言版本，已在50种语言上进行了预训练。</td>
<td align="center">✅</td>
</tr>
</tbody></table>
<p>正如你从这张表中看到的，大多数用于摘要的Transformer模型（以及大多数NLP任务）都是单语的。如果你的任务涉及英语或德语等“资源丰富的”语言，这很不错，但对于世界上其他成千上万种语言来说则不然。幸运的是，有一类多语言Transformer模型，比如mT5和mBART，可以解决这个问题。这些模型使用语言建模进行预训练，但与传统方法不同的是，它们不是在一个语言的语料库上进行训练，而是同时在超过50种语言的文本上进行联合训练。</p>
<p>我们将重点关注mT5，这是一种基于T5的有趣架构，该架构在文本到文本框架中进行了预训练。在T5中，每个NLP任务都以提示前缀的形式表述，例如“summarize”，该提示条件模型将生成的文本与提示相匹配。如下图所示，这使得T5非常通用，因为您可以使用一个模型解决许多任务！</p>
<p><img src="https://cos.luyf-lemon-love.space/images/20250504160745.png"></p>
<p>mT5不使用前缀，但拥有与T5类似的多样性，并具有多语言的优势。现在我们已经选定了模型，让我们看看如何准备数据进行训练。</p>
<blockquote>
<p>✏️ 试试看！完成本节后，比较mT5和mBART的性能，使用相同的技术对后者进行微调。作为额外的挑战，您还可以尝试仅使用英文评论对T5进行微调。由于T5有一个特殊的前缀提示，您需要在下面的预处理步骤中在输入示例前添加“summarize:”。</p>
</blockquote>
<h2 id="预处理数据"><a href="#预处理数据" class="headerlink" title="预处理数据"></a>预处理数据</h2><p>我们接下来的任务是将我们的评论及其标题进行分词和编码。像往常一样，我们首先加载与预训练模型检查点相关的分词器。我们将使用mt5-small作为我们的检查点，以便我们能够在合理的时间内对模型进行微调：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer

model_checkpoint <span class="token operator">=</span> <span class="token string">"google/mt5-small"</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_checkpoint<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>在NLP项目的早期阶段，一个好的做法是使用少量数据训练一系列“小型”模型。这可以让你更快地调试和迭代，朝着端到端的工作流程迈进。一旦你对结果感到满意，你可以随时通过更改模型检查点来扩大模型的规模！</p>
</blockquote>
<p>让我们在一个小例子上测试一下 mT5 分词器：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span><span class="token string">"I loved reading the Hunger Games!"</span><span class="token punctuation">)</span>
inputs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">&#123;</span><span class="token string">'input_ids'</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token number">336</span>, <span class="token number">259</span>, <span class="token number">28387</span>, <span class="token number">11807</span>, <span class="token number">287</span>, <span class="token number">62893</span>, <span class="token number">295</span>, <span class="token number">12507</span>, <span class="token number">1</span><span class="token punctuation">]</span>, <span class="token string">'attention_mask'</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>在这里，我们可以看到我们在第3章首次进行微调实验时遇到的熟悉的input_ids和attention_mask。让我们使用令牌化器的convert_ids_to_tokens()函数解码这些输入ID，看看我们正在使用的是哪种令牌化器：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">tokenizer<span class="token punctuation">.</span>convert_ids_to_tokens<span class="token punctuation">(</span>inputs<span class="token punctuation">.</span>input_ids<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span><span class="token string">'▁I'</span>, <span class="token string">'▁'</span>, <span class="token string">'loved'</span>, <span class="token string">'▁reading'</span>, <span class="token string">'▁the'</span>, <span class="token string">'▁Hung'</span>, <span class="token string">'er'</span>, <span class="token string">'▁Games'</span>, <span class="token string">'&lt;/s>'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>特殊的 Unicode 字符 ▁ 和序列结束标记 </s> 表明我们正在使用 SentencePiece 分词器，它基于第 6 章讨论的 Unigram 分词算法。Unigram 对于多语言语料库尤其有用，因为它使 SentencePiece 能够忽略重音符号、标点符号，并且适用于许多像日语一样本身不包含空格字符的语言。</p>
<p>为了对我们的语料进行分词，我们需要处理与摘要任务相关的一个细节问题：由于我们的标签也是文本，因此它们有可能超出模型的最大上下文长度限制。这意味着我们需要对评论内容和标题同时进行截断处理，以确保输入不会过长。Hugging Face Transformers 中的分词器提供了一个便捷的 text_target 参数，允许你将标签与输入内容并行地进行分词处理。以下是如何为 mT5 模型处理输入和目标文本的一个示例：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">max_input_length <span class="token operator">=</span> <span class="token number">512</span>
max_target_length <span class="token operator">=</span> <span class="token number">30</span>


<span class="token keyword">def</span> <span class="token function">preprocess_function</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model_inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>
        examples<span class="token punctuation">[</span><span class="token string">"review_body"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        max_length<span class="token operator">=</span>max_input_length<span class="token punctuation">,</span>
        truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    labels <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>
        examples<span class="token punctuation">[</span><span class="token string">"review_title"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> max_length<span class="token operator">=</span>max_target_length<span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span>
    <span class="token punctuation">)</span>
    model_inputs<span class="token punctuation">[</span><span class="token string">"labels"</span><span class="token punctuation">]</span> <span class="token operator">=</span> labels<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> model_inputs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>让我们逐步解析这段代码，理解其中发生了什么。首先，我们定义了 <code>max_input_length</code> 和 <code>max_target_length</code> 的值，它们分别设定了评论内容和标题的最大长度限制。由于评论正文通常比标题长得多，因此我们根据这个特点对这两个值进行了相应的设置。</p>
<p>接下来，在 <code>preprocess_function()</code> 中，我们就可以使用在整个课程中频繁使用的便捷方法 <code>Dataset.map()</code>，来轻松地对整个语料库进行分词处理：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">tokenized_datasets <span class="token operator">=</span> books_dataset<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>preprocess_function<span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>现在语料库已经完成了预处理，让我们来看一些常用于摘要任务的评估指标。我们会发现，在衡量机器生成文本的质量时，并不存在一种万能的评估方法。</p>
<blockquote>
<p>💡 你可能已经注意到，我们在上面的 <code>Dataset.map()</code> 函数中使用了 <code>batched=True</code>。这会将样本以每批 1,000 条（默认值）的方式进行分批处理，并允许我们利用 Hugging Face Transformers 中快速分词器所支持的多线程功能。在可能的情况下，尽量使用 <code>batched=True</code>，以提升预处理的效率！</p>
</blockquote>
<h2 id="文本摘要的度量标准"><a href="#文本摘要的度量标准" class="headerlink" title="文本摘要的度量标准"></a>文本摘要的度量标准</h2><p>与本课程中介绍的大多数其他任务相比，评估摘要或翻译等文本生成任务的性能并没有那么直接。例如，对于一条评论：“I loved reading the Hunger Games”，可能存在多个合理的摘要，比如“I loved the Hunger Games”或者“Hunger Games is a great read”。显然，在生成的摘要和标签之间进行完全匹配（exact match）并不是一个好的解决方案——即使对人类来说，这种指标下的表现也可能很差，因为我们每个人的写作风格都不尽相同。</p>
<p>在摘要任务中，最常用的评估指标之一是 <strong>ROUGE 分数</strong>（Recall-Oriented Understudy for Gisting Evaluation，意为“面向召回率的摘要评测助手”）。该指标的基本思想是将生成的摘要与一组通常由人工撰写的参考摘要进行比较。</p>
<p>为了更具体地说明这一点，假设我们要比较以下两个摘要：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">generated_summary <span class="token operator">=</span> <span class="token string">"I absolutely loved reading the Hunger Games"</span>
reference_summary <span class="token operator">=</span> <span class="token string">"I loved reading the Hunger Games"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>一种比较方式是统计两个摘要中重叠的词语数量，在这个例子中有 6 个重叠词。然而，这种方法显得有些粗糙。因此，ROUGE 指标转而基于<strong>精确率（precision）</strong>和<strong>召回率（recall）</strong>来衡量重叠部分的匹配程度。</p>
<blockquote>
<p>🙋 如果你第一次听说“精确率”和“召回率”也不用担心——接下来我们会通过一些具体的例子来清楚地解释它们。这两个指标通常出现在分类任务中，如果你想知道它们在分类场景下的定义，我们推荐查阅 scikit-learn 的<a href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html">官方指南</a>。</p>
</blockquote>
<p>在 ROUGE 中，<strong>召回率（recall）</strong>用于衡量生成的摘要覆盖参考摘要内容的程度。如果只是对词语进行比较，召回率可以通过以下公式计算：</p>
<p>$$ \mathrm{Recall} &#x3D; \frac{\mathrm{Number,of,overlapping, words}}{\mathrm{Total, number, of, words, in, reference, summary}} $$</p>
<p>对于我们上面这个简单例子，这个公式给出的召回率是 6&#x2F;6 &#x3D; 1，也就是完美召回：模型生成的摘要包含了参考摘要中的所有词语。这听起来很好，但我们可以想象一个情况：如果生成的摘要其实是“<strong>I really really loved reading the Hunger Games all night</strong>”，这也仍然会得到完美的召回率，但从摘要的角度来看，这段文字显然更啰嗦、质量更差。</p>
<p>为了解决这类问题，我们还会计算<strong>精确率（precision）</strong>。在 ROUGE 的语境中，精确率衡量的是生成的摘要中有多少内容是相关的：</p>
<p>$$ \mathrm{Precision} &#x3D; \frac{\mathrm{Number,of,overlapping, words}}{\mathrm{Total, number, of, words, in, generated, summary}} $$</p>
<p>将这个公式应用到我们那个啰嗦的摘要上，得到的精确率是 6&#x2F;10 &#x3D; 0.6，这明显比简洁版本的精确率 6&#x2F;7 ≈ 0.86 要差不少。在实际应用中，通常会同时计算精确率和召回率，然后报告它们的调和平均数 —— <strong>F1 分数（F1-score）</strong>。</p>
<p>我们可以很容易地在 🤗 Datasets 中实现这一点，首先需要安装 <code>rouge_score</code> 包：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">!pip install rouge_score<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>然后按照以下方式加载 ROUGE 指标：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> evaluate

rouge_score <span class="token operator">=</span> evaluate<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"rouge"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>然后我们可以使用 <code>rouge_score.compute()</code> 函数一次性计算所有指标：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">scores <span class="token operator">=</span> rouge_score<span class="token punctuation">.</span>compute<span class="token punctuation">(</span>
    predictions<span class="token operator">=</span><span class="token punctuation">[</span>generated_summary<span class="token punctuation">]</span><span class="token punctuation">,</span> references<span class="token operator">=</span><span class="token punctuation">[</span>reference_summary<span class="token punctuation">]</span>
<span class="token punctuation">)</span>
scores<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token punctuation">&#123;</span><span class="token string">'rouge1'</span><span class="token punctuation">:</span> AggregateScore<span class="token punctuation">(</span>low<span class="token operator">=</span>Score<span class="token punctuation">(</span>precision<span class="token operator">=</span><span class="token number">0.86</span><span class="token punctuation">,</span> recall<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> fmeasure<span class="token operator">=</span><span class="token number">0.92</span><span class="token punctuation">)</span><span class="token punctuation">,</span> mid<span class="token operator">=</span>Score<span class="token punctuation">(</span>precision<span class="token operator">=</span><span class="token number">0.86</span><span class="token punctuation">,</span> recall<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> fmeasure<span class="token operator">=</span><span class="token number">0.92</span><span class="token punctuation">)</span><span class="token punctuation">,</span> high<span class="token operator">=</span>Score<span class="token punctuation">(</span>precision<span class="token operator">=</span><span class="token number">0.86</span><span class="token punctuation">,</span> recall<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> fmeasure<span class="token operator">=</span><span class="token number">0.92</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token string">'rouge2'</span><span class="token punctuation">:</span> AggregateScore<span class="token punctuation">(</span>low<span class="token operator">=</span>Score<span class="token punctuation">(</span>precision<span class="token operator">=</span><span class="token number">0.67</span><span class="token punctuation">,</span> recall<span class="token operator">=</span><span class="token number">0.8</span><span class="token punctuation">,</span> fmeasure<span class="token operator">=</span><span class="token number">0.73</span><span class="token punctuation">)</span><span class="token punctuation">,</span> mid<span class="token operator">=</span>Score<span class="token punctuation">(</span>precision<span class="token operator">=</span><span class="token number">0.67</span><span class="token punctuation">,</span> recall<span class="token operator">=</span><span class="token number">0.8</span><span class="token punctuation">,</span> fmeasure<span class="token operator">=</span><span class="token number">0.73</span><span class="token punctuation">)</span><span class="token punctuation">,</span> high<span class="token operator">=</span>Score<span class="token punctuation">(</span>precision<span class="token operator">=</span><span class="token number">0.67</span><span class="token punctuation">,</span> recall<span class="token operator">=</span><span class="token number">0.8</span><span class="token punctuation">,</span> fmeasure<span class="token operator">=</span><span class="token number">0.73</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token string">'rougeL'</span><span class="token punctuation">:</span> AggregateScore<span class="token punctuation">(</span>low<span class="token operator">=</span>Score<span class="token punctuation">(</span>precision<span class="token operator">=</span><span class="token number">0.86</span><span class="token punctuation">,</span> recall<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> fmeasure<span class="token operator">=</span><span class="token number">0.92</span><span class="token punctuation">)</span><span class="token punctuation">,</span> mid<span class="token operator">=</span>Score<span class="token punctuation">(</span>precision<span class="token operator">=</span><span class="token number">0.86</span><span class="token punctuation">,</span> recall<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> fmeasure<span class="token operator">=</span><span class="token number">0.92</span><span class="token punctuation">)</span><span class="token punctuation">,</span> high<span class="token operator">=</span>Score<span class="token punctuation">(</span>precision<span class="token operator">=</span><span class="token number">0.86</span><span class="token punctuation">,</span> recall<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> fmeasure<span class="token operator">=</span><span class="token number">0.92</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token string">'rougeLsum'</span><span class="token punctuation">:</span> AggregateScore<span class="token punctuation">(</span>low<span class="token operator">=</span>Score<span class="token punctuation">(</span>precision<span class="token operator">=</span><span class="token number">0.86</span><span class="token punctuation">,</span> recall<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> fmeasure<span class="token operator">=</span><span class="token number">0.92</span><span class="token punctuation">)</span><span class="token punctuation">,</span> mid<span class="token operator">=</span>Score<span class="token punctuation">(</span>precision<span class="token operator">=</span><span class="token number">0.86</span><span class="token punctuation">,</span> recall<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> fmeasure<span class="token operator">=</span><span class="token number">0.92</span><span class="token punctuation">)</span><span class="token punctuation">,</span> high<span class="token operator">=</span>Score<span class="token punctuation">(</span>precision<span class="token operator">=</span><span class="token number">0.86</span><span class="token punctuation">,</span> recall<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> fmeasure<span class="token operator">=</span><span class="token number">0.92</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<p>哇，这个输出中包含了很多信息——它们都代表什么意思呢？首先，🤗 Datasets 实际上会为精确率（precision）、召回率（recall）和 F1 分数（F1-score）计算置信区间，这些就是你在这里看到的 low（低）、mid（中）和 high（高）这三个属性。此外，🤗 Datasets 还计算了多种 ROUGE 分数（ROUGE scores），这些分数在比较生成摘要和参考摘要时基于不同粒度的文本单位。其中，rouge1 变体表示的是单字（unigram）的重叠情况——这其实只是对“单词重叠”的一种高级说法而已，也正是我们上面讨论过的评估指标。为了验证这一点，我们可以提取出分数中的 mid 值：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">scores<span class="token punctuation">[</span><span class="token string">"rouge1"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>mid<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<pre class="line-numbers language-python" data-language="python"><code class="language-python">Score<span class="token punctuation">(</span>precision<span class="token operator">=</span><span class="token number">0.86</span><span class="token punctuation">,</span> recall<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> fmeasure<span class="token operator">=</span><span class="token number">0.92</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>太好了，精确率和召回率的数值对上了！那么那些其他的 ROUGE 分数又是什么意思呢？  </p>
<ul>
<li><strong>rouge2</strong> 衡量的是 <strong>bigram（双字）的重叠</strong>，也就是说，它关注的是连续两个词组成的词对之间的重叠情况。  </li>
<li><strong>rougeL</strong> 和 <strong>rougeLsum</strong> 则衡量的是生成摘要和参考摘要之间 <strong>最长的连续匹配词序列</strong>，它们通过寻找两者中最长的公共子串来计算得分。  <ul>
<li>其中，<strong>rougeLsum</strong> 中的 “sum” 表示这个指标是针对整个摘要整体计算的，  </li>
<li>而 <strong>rougeL</strong> 则是在每个单独的句子上计算，然后取平均值。</li>
</ul>
</li>
</ul>
<blockquote>
<p>✏️ 动手试一试！自己创建一个生成摘要和参考摘要的例子，然后看看得出的 ROUGE 分数是否与根据精确率和召回率公式手动计算的结果一致。如果你想挑战一下，可以将文本拆分为二元组（bigrams），并对比 rouge2 指标的精确率和召回率。</p>
</blockquote>
<p>我们将使用这些 ROUGE 分数来跟踪模型的性能，但在那之前，让我们先做一件每位优秀的 NLP 从业者都应该做的事：创建一个强大而简洁的基线模型（baseline）！</p>
<h3 id="创建强大的基线"><a href="#创建强大的基线" class="headerlink" title="创建强大的基线"></a>创建强大的基线</h3><p>一个常见的文本摘要基线方法是简单地取文章的前三句话，这通常被称为“前导三句”（lead-3）基线。我们可以使用句号来识别句子边界，但这种方法在处理像 “U.S.” 或 “U.N.” 这样的缩写时会失败。因此，我们将改用 <strong>nltk</strong> 库，它包含了一个更优秀的算法来处理这些情况。你可以使用 pip 按如下方式安装这个库：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">!pip install nltk<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>然后下载标点符号规则：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> nltk

nltk<span class="token punctuation">.</span>download<span class="token punctuation">(</span><span class="token string">"punkt"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>接下来，我们从nltk导入句子分词器，并创建一个简单的函数来提取评论中的前三句话。在文本摘要中，通常会用换行符来分隔每个摘要，所以我们也应该包括这一点，并在一个训练示例上进行测试：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> nltk<span class="token punctuation">.</span>tokenize <span class="token keyword">import</span> sent_tokenize


<span class="token keyword">def</span> <span class="token function">three_sentence_summary</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token string">"\n"</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>sent_tokenize<span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>


<span class="token keyword">print</span><span class="token punctuation">(</span>three_sentence_summary<span class="token punctuation">(</span>books_dataset<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"review_body"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token string">'I grew up reading Koontz, and years ago, I stopped,convinced i had "outgrown" him.'</span>
<span class="token string">'Still,when a friend was looking for something suspenseful too read, I suggested Koontz.'</span>
<span class="token string">'She found Strangers.'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>这看起来是可行的，所以让我们现在实现一个函数，从数据集中提取这些”摘要”，并计算基准的ROUGE分数：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">evaluate_baseline</span><span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> metric<span class="token punctuation">)</span><span class="token punctuation">:</span>
    summaries <span class="token operator">=</span> <span class="token punctuation">[</span>three_sentence_summary<span class="token punctuation">(</span>text<span class="token punctuation">)</span> <span class="token keyword">for</span> text <span class="token keyword">in</span> dataset<span class="token punctuation">[</span><span class="token string">"review_body"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> metric<span class="token punctuation">.</span>compute<span class="token punctuation">(</span>predictions<span class="token operator">=</span>summaries<span class="token punctuation">,</span> references<span class="token operator">=</span>dataset<span class="token punctuation">[</span><span class="token string">"review_title"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>然后我们可以使用这个函数来计算验证集上的ROUGE分数，并使用Pandas对它们进行一些美化：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd

score <span class="token operator">=</span> evaluate_baseline<span class="token punctuation">(</span>books_dataset<span class="token punctuation">[</span><span class="token string">"validation"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> rouge_score<span class="token punctuation">)</span>
rouge_names <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"rouge1"</span><span class="token punctuation">,</span> <span class="token string">"rouge2"</span><span class="token punctuation">,</span> <span class="token string">"rougeL"</span><span class="token punctuation">,</span> <span class="token string">"rougeLsum"</span><span class="token punctuation">]</span>
rouge_dict <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">(</span>rn<span class="token punctuation">,</span> <span class="token builtin">round</span><span class="token punctuation">(</span>score<span class="token punctuation">[</span>rn<span class="token punctuation">]</span><span class="token punctuation">.</span>mid<span class="token punctuation">.</span>fmeasure <span class="token operator">*</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> rn <span class="token keyword">in</span> rouge_names<span class="token punctuation">)</span>
rouge_dict<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token punctuation">&#123;</span><span class="token string">'rouge1'</span><span class="token punctuation">:</span> <span class="token number">16.74</span><span class="token punctuation">,</span> <span class="token string">'rouge2'</span><span class="token punctuation">:</span> <span class="token number">8.83</span><span class="token punctuation">,</span> <span class="token string">'rougeL'</span><span class="token punctuation">:</span> <span class="token number">15.6</span><span class="token punctuation">,</span> <span class="token string">'rougeLsum'</span><span class="token punctuation">:</span> <span class="token number">15.96</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>我们可以看到rouge2的得分明显低于其他得分；这可能是因为评论标题通常比较简短，因此lead-3的基线过于冗长。现在我们有了一个很好的基线作为基础，让我们把注意力转向微调mT5吧！</p>
<h2 id="使用Trainer-API微调mT5"><a href="#使用Trainer-API微调mT5" class="headerlink" title="使用Trainer API微调mT5"></a>使用Trainer API微调mT5</h2><p>为摘要任务微调模型与我们在本章中介绍的其他任务非常相似。我们需要做的第一件事是从 mt5-small 检查点加载预训练模型。由于摘要是一项序列到序列的任务，我们可以使用 AutoModelForSeq2SeqLM 类来加载模型，该类将自动下载并缓存权重：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForSeq2SeqLM

model <span class="token operator">=</span> AutoModelForSeq2SeqLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_checkpoint<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>💡如果你想知道为什么在下游任务中看不到任何关于微调模型的警告，那是因为对于序列到序列的任务，我们保留了网络的所有权重。相比之下，在第3章的文本分类模型中，预训练模型的头部被替换成了一个随机初始化的网络。</p>
</blockquote>
<p>我们接下来需要做的是登录 Hugging Face Hub。如果你在笔记本中运行这段代码，你可以使用以下的实用函数来完成：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> huggingface_hub <span class="token keyword">import</span> notebook_login

notebook_login<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>这将显示一个小部件，您可以在其中输入您的凭证。或者，您可以在终端中运行此命令并在那里登录：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">huggingface-cli login<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>我们需要生成摘要以便在训练过程中计算ROUGE分数。幸运的是，🤗 Transformers提供了专门的Seq2SeqTrainingArguments和Seq2SeqTrainer类，可以自动为我们完成这项工作！为了了解这是如何工作的，让我们首先为我们的实验定义超参数和其他参数：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> Seq2SeqTrainingArguments

batch_size <span class="token operator">=</span> <span class="token number">8</span>
num_train_epochs <span class="token operator">=</span> <span class="token number">8</span>
<span class="token comment"># Show the training loss with every epoch</span>
logging_steps <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>tokenized_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">//</span> batch_size
model_name <span class="token operator">=</span> model_checkpoint<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"/"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>

args <span class="token operator">=</span> Seq2SeqTrainingArguments<span class="token punctuation">(</span>
    output_dir<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>model_name<span class="token punctuation">&#125;</span></span><span class="token string">-finetuned-amazon-en-es"</span></span><span class="token punctuation">,</span>
    evaluation_strategy<span class="token operator">=</span><span class="token string">"epoch"</span><span class="token punctuation">,</span>
    learning_rate<span class="token operator">=</span><span class="token number">5.6e-5</span><span class="token punctuation">,</span>
    per_device_train_batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>
    per_device_eval_batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>
    weight_decay<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>
    save_total_limit<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
    num_train_epochs<span class="token operator">=</span>num_train_epochs<span class="token punctuation">,</span>
    predict_with_generate<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    logging_steps<span class="token operator">=</span>logging_steps<span class="token punctuation">,</span>
    push_to_hub<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>在这里，我们设置了predict_with_generate参数，表示在评估过程中应该生成摘要，以便我们可以计算每个epoch的ROUGE分数。正如第1章所讨论的，解码器通过逐一预测令牌来进行推理，这通过模型的generate()方法实现。设置predict_with_generate&#x3D;True告诉Seq2SeqTrainer在评估时使用该方法。<br>我们还调整了一些默认超参数，如学习率、训练轮数和权重衰减，并将 save_total_limit 选项设置为在训练过程中只保存最多 3 个检查点——这是因为即使是 mT5 的“小”版本也需要大约 1GB 的硬盘空间，通过限制保存的副本数量，我们可以节省一些空间。</p>
<p>push_to_hub&#x3D;True 参数将允许我们在训练后将模型推送到 Hub；你可以在输出目录定义的位置的用户配置文件下找到存储库。请注意，你可以使用 hub_model_id 参数指定要推送到的存储库的名称（特别是，你必须使用这个参数来推送到一个组织）。例如，当我们将模型推送到 huggingface-course 组织时，我们在 Seq2SeqTrainingArguments 中添加了 hub_model_id&#x3D;”huggingface-course&#x2F;mt5-finetuned-amazon-en-es”。</p>
<p>接下来我们需要做的是为训练器提供一个 <code>compute_metrics()</code> 函数，以便我们可以在训练过程中对模型进行评估。对于摘要任务来说，这比简单地在模型预测结果上调用 <code>rouge_score.compute()</code> 要复杂一些，因为我们需要先将模型输出和标签解码为文本，然后才能计算 ROUGE 分数。以下函数正是实现了这一功能，并且还利用了来自 <code>nltk</code> 的 <code>sent_tokenize()</code> 函数，将摘要中的每个句子用换行符分隔开来：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np


<span class="token keyword">def</span> <span class="token function">compute_metrics</span><span class="token punctuation">(</span>eval_pred<span class="token punctuation">)</span><span class="token punctuation">:</span>
    predictions<span class="token punctuation">,</span> labels <span class="token operator">=</span> eval_pred
    <span class="token comment"># Decode generated summaries into text</span>
    decoded_preds <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>batch_decode<span class="token punctuation">(</span>predictions<span class="token punctuation">,</span> skip_special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token comment"># Replace -100 in the labels as we can't decode them</span>
    labels <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>labels <span class="token operator">!=</span> <span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">,</span> labels<span class="token punctuation">,</span> tokenizer<span class="token punctuation">.</span>pad_token_id<span class="token punctuation">)</span>
    <span class="token comment"># Decode reference summaries into text</span>
    decoded_labels <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>batch_decode<span class="token punctuation">(</span>labels<span class="token punctuation">,</span> skip_special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token comment"># ROUGE expects a newline after each sentence</span>
    decoded_preds <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"\n"</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>sent_tokenize<span class="token punctuation">(</span>pred<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> pred <span class="token keyword">in</span> decoded_preds<span class="token punctuation">]</span>
    decoded_labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"\n"</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>sent_tokenize<span class="token punctuation">(</span>label<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> label <span class="token keyword">in</span> decoded_labels<span class="token punctuation">]</span>
    <span class="token comment"># Compute ROUGE scores</span>
    result <span class="token operator">=</span> rouge_score<span class="token punctuation">.</span>compute<span class="token punctuation">(</span>
        predictions<span class="token operator">=</span>decoded_preds<span class="token punctuation">,</span> references<span class="token operator">=</span>decoded_labels<span class="token punctuation">,</span> use_stemmer<span class="token operator">=</span><span class="token boolean">True</span>
    <span class="token punctuation">)</span>
    <span class="token comment"># Extract the median scores</span>
    result <span class="token operator">=</span> <span class="token punctuation">&#123;</span>key<span class="token punctuation">:</span> value<span class="token punctuation">.</span>mid<span class="token punctuation">.</span>fmeasure <span class="token operator">*</span> <span class="token number">100</span> <span class="token keyword">for</span> key<span class="token punctuation">,</span> value <span class="token keyword">in</span> result<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span>
    <span class="token keyword">return</span> <span class="token punctuation">&#123;</span>k<span class="token punctuation">:</span> <span class="token builtin">round</span><span class="token punctuation">(</span>v<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> result<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>接下来，我们需要为我们的序列到序列任务定义一个数据整理器。由于mT5是一个编码器-解码器Transformer模型，在准备我们的批次时需要注意的一个细节是：在解码过程中，我们需要将标签向右移动一位。这是为了确保解码器只看到之前的真实标签，而不会看到当前或未来的标签，否则模型很容易记住这些信息。这类似于在因果语言建模等任务中对输入应用掩码自注意力机制的方式。</p>
<p>幸运的是，🤗 Transformers 提供了一个 DataCollatorForSeq2Seq 整理器，它将为我们动态填充输入和标记。要实例化这个整理器，我们只需要提供令牌化器和模型：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> DataCollatorForSeq2Seq

data_collator <span class="token operator">=</span> DataCollatorForSeq2Seq<span class="token punctuation">(</span>tokenizer<span class="token punctuation">,</span> model<span class="token operator">=</span>model<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>让我们看看当给这个数据整理器（collator）提供一个小批量示例时，它会产生什么样的输出。首先，我们需要移除包含字符串的列，因为整理器不知道如何对这些元素进行填充（padding）：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">tokenized_datasets <span class="token operator">=</span> tokenized_datasets<span class="token punctuation">.</span>remove_columns<span class="token punctuation">(</span>
    books_dataset<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>column_names
<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>由于数据整理器（collator）期望接收一个字典列表，其中每个字典代表数据集中的一个单独样本，因此在将其传递给数据整理器之前，我们还需要将数据整理成预期的格式：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">features <span class="token operator">=</span> <span class="token punctuation">[</span>tokenized_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
data_collator<span class="token punctuation">(</span>features<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token punctuation">&#123;</span><span class="token string">'attention_mask'</span><span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span>
         <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span>
         <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'input_ids'</span><span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span>  <span class="token number">1494</span><span class="token punctuation">,</span>    <span class="token number">259</span><span class="token punctuation">,</span>   <span class="token number">8622</span><span class="token punctuation">,</span>    <span class="token number">390</span><span class="token punctuation">,</span>    <span class="token number">259</span><span class="token punctuation">,</span>    <span class="token number">262</span><span class="token punctuation">,</span>   <span class="token number">2316</span><span class="token punctuation">,</span>   <span class="token number">3435</span><span class="token punctuation">,</span>    <span class="token number">955</span><span class="token punctuation">,</span>
            <span class="token number">772</span><span class="token punctuation">,</span>    <span class="token number">281</span><span class="token punctuation">,</span>    <span class="token number">772</span><span class="token punctuation">,</span>   <span class="token number">1617</span><span class="token punctuation">,</span>    <span class="token number">263</span><span class="token punctuation">,</span>    <span class="token number">305</span><span class="token punctuation">,</span>  <span class="token number">14701</span><span class="token punctuation">,</span>    <span class="token number">260</span><span class="token punctuation">,</span>   <span class="token number">1385</span><span class="token punctuation">,</span>
           <span class="token number">3031</span><span class="token punctuation">,</span>    <span class="token number">259</span><span class="token punctuation">,</span>  <span class="token number">24146</span><span class="token punctuation">,</span>    <span class="token number">332</span><span class="token punctuation">,</span>   <span class="token number">1037</span><span class="token punctuation">,</span>    <span class="token number">259</span><span class="token punctuation">,</span>  <span class="token number">43906</span><span class="token punctuation">,</span>    <span class="token number">305</span><span class="token punctuation">,</span>    <span class="token number">336</span><span class="token punctuation">,</span>
            <span class="token number">260</span><span class="token punctuation">,</span>      <span class="token number">1</span><span class="token punctuation">,</span>      <span class="token number">0</span><span class="token punctuation">,</span>      <span class="token number">0</span><span class="token punctuation">,</span>      <span class="token number">0</span><span class="token punctuation">,</span>      <span class="token number">0</span><span class="token punctuation">,</span>      <span class="token number">0</span><span class="token punctuation">,</span>      <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span>   <span class="token number">259</span><span class="token punctuation">,</span>  <span class="token number">27531</span><span class="token punctuation">,</span>  <span class="token number">13483</span><span class="token punctuation">,</span>    <span class="token number">259</span><span class="token punctuation">,</span>   <span class="token number">7505</span><span class="token punctuation">,</span>    <span class="token number">260</span><span class="token punctuation">,</span> <span class="token number">112240</span><span class="token punctuation">,</span>  <span class="token number">15192</span><span class="token punctuation">,</span>    <span class="token number">305</span><span class="token punctuation">,</span>
          <span class="token number">53198</span><span class="token punctuation">,</span>    <span class="token number">276</span><span class="token punctuation">,</span>    <span class="token number">259</span><span class="token punctuation">,</span>  <span class="token number">74060</span><span class="token punctuation">,</span>    <span class="token number">263</span><span class="token punctuation">,</span>    <span class="token number">260</span><span class="token punctuation">,</span>    <span class="token number">459</span><span class="token punctuation">,</span>  <span class="token number">25640</span><span class="token punctuation">,</span>    <span class="token number">776</span><span class="token punctuation">,</span>
           <span class="token number">2119</span><span class="token punctuation">,</span>    <span class="token number">336</span><span class="token punctuation">,</span>    <span class="token number">259</span><span class="token punctuation">,</span>   <span class="token number">2220</span><span class="token punctuation">,</span>    <span class="token number">259</span><span class="token punctuation">,</span>  <span class="token number">18896</span><span class="token punctuation">,</span>    <span class="token number">288</span><span class="token punctuation">,</span>   <span class="token number">4906</span><span class="token punctuation">,</span>    <span class="token number">288</span><span class="token punctuation">,</span>
           <span class="token number">1037</span><span class="token punctuation">,</span>   <span class="token number">3931</span><span class="token punctuation">,</span>    <span class="token number">260</span><span class="token punctuation">,</span>   <span class="token number">7083</span><span class="token punctuation">,</span> <span class="token number">101476</span><span class="token punctuation">,</span>   <span class="token number">1143</span><span class="token punctuation">,</span>    <span class="token number">260</span><span class="token punctuation">,</span>      <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'labels'</span><span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">7483</span><span class="token punctuation">,</span>   <span class="token number">259</span><span class="token punctuation">,</span>  <span class="token number">2364</span><span class="token punctuation">,</span> <span class="token number">15695</span><span class="token punctuation">,</span>     <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span>  <span class="token number">259</span><span class="token punctuation">,</span> <span class="token number">27531</span><span class="token punctuation">,</span> <span class="token number">13483</span><span class="token punctuation">,</span>   <span class="token number">259</span><span class="token punctuation">,</span>  <span class="token number">7505</span><span class="token punctuation">,</span>     <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'decoder_input_ids'</span><span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span>    <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token number">7483</span><span class="token punctuation">,</span>   <span class="token number">259</span><span class="token punctuation">,</span>  <span class="token number">2364</span><span class="token punctuation">,</span> <span class="token number">15695</span><span class="token punctuation">,</span>     <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span>    <span class="token number">0</span><span class="token punctuation">,</span>   <span class="token number">259</span><span class="token punctuation">,</span> <span class="token number">27531</span><span class="token punctuation">,</span> <span class="token number">13483</span><span class="token punctuation">,</span>   <span class="token number">259</span><span class="token punctuation">,</span>  <span class="token number">7505</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>这里需要注意的主要一点是，第一个样本的长度长于第二个样本，因此第二个样本的 <code>input_ids</code> 和 <code>attention_mask</code> 在右侧用 <code>[PAD]</code> 标记进行了填充（其 ID 为 0）。同样，我们可以看到 <code>labels</code> 被填充了 <code>-100</code>，这是为了确保损失函数忽略这些填充标记。最后，我们还可以看到一个新的 <code>decoder_input_ids</code> 字段，它通过在第一个位置插入 <code>[PAD]</code> 标记，将标签整体向右移动了一位。</p>
<p>我们终于有了训练所需的所有材料！现在只需要用标准参数实例化训练器即可：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> Seq2SeqTrainer

trainer <span class="token operator">=</span> Seq2SeqTrainer<span class="token punctuation">(</span>
    model<span class="token punctuation">,</span>
    args<span class="token punctuation">,</span>
    train_dataset<span class="token operator">=</span>tokenized_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    eval_dataset<span class="token operator">=</span>tokenized_datasets<span class="token punctuation">[</span><span class="token string">"validation"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    data_collator<span class="token operator">=</span>data_collator<span class="token punctuation">,</span>
    tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span>
    compute_metrics<span class="token operator">=</span>compute_metrics<span class="token punctuation">,</span>
<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>并启动我们的训练运行：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>在训练过程中，您应该看到训练损失减少，每个 epoch 的 ROUGE 分数增加。训练完成后，您可以通过运行 Trainer.evaluate() 来查看最终的 ROUGE 分数：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">trainer<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">&#123;</span><span class="token string">'eval_loss'</span><span class="token builtin class-name">:</span> <span class="token number">3.028524398803711</span>,
 <span class="token string">'eval_rouge1'</span><span class="token builtin class-name">:</span> <span class="token number">16.9728</span>,
 <span class="token string">'eval_rouge2'</span><span class="token builtin class-name">:</span> <span class="token number">8.2969</span>,
 <span class="token string">'eval_rougeL'</span><span class="token builtin class-name">:</span> <span class="token number">16.8366</span>,
 <span class="token string">'eval_rougeLsum'</span><span class="token builtin class-name">:</span> <span class="token number">16.851</span>,
 <span class="token string">'eval_gen_len'</span><span class="token builtin class-name">:</span> <span class="token number">10.1597</span>,
 <span class="token string">'eval_runtime'</span><span class="token builtin class-name">:</span> <span class="token number">6.1054</span>,
 <span class="token string">'eval_samples_per_second'</span><span class="token builtin class-name">:</span> <span class="token number">38.982</span>,
 <span class="token string">'eval_steps_per_second'</span><span class="token builtin class-name">:</span> <span class="token number">4.914</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>从分数我们可以看到，我们的模型轻松地超过了我们的 lead-3 基准——很不错！最后要做的是将模型权重推送到 Hub，具体步骤如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">trainer<span class="token punctuation">.</span>push_to_hub<span class="token punctuation">(</span>commit_message<span class="token operator">=</span><span class="token string">"Training complete"</span><span class="token punctuation">,</span> tags<span class="token operator">=</span><span class="token string">"summarization"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token string">'https://huggingface.co/huggingface-course/mt5-finetuned-amazon-en-es/commit/aa0536b829b28e73e1e4b94b8a5aacec420d40e0'</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>这会将检查点和配置文件保存到 <code>output_dir</code>，然后将所有文件上传到模型中心（Hub）。通过指定 <code>tags</code> 参数，我们还可以确保模型中心上的小部件（widget）适用于摘要流水线，而不是与 mT5 架构关联的默认文本生成流水线（有关模型标签的更多信息，请参见 <a href="https://huggingface.co/docs/hub/main#how-is-a-models-type-of-inference-api-and-widget-determined">🤗 Hub 文档</a>）。<code>trainer.push_to_hub()</code> 的输出是一个指向 Git 提交哈希的 URL，因此你可以轻松查看对模型仓库所做的更改！</p>
<p>在结束这个部分之前，让我们来看看如何使用🤗 Accelerate提供的低级功能来微调mT5。</p>
<h2 id="使用🤗-Accelerate对mT5进行微调"><a href="#使用🤗-Accelerate对mT5进行微调" class="headerlink" title="使用🤗 Accelerate对mT5进行微调"></a>使用🤗 Accelerate对mT5进行微调</h2><p>在🤗 Accelerate 中微调我们的模型与我们在第3章遇到的文本分类示例非常相似。主要的区别是需要在训练过程中显式地生成我们的摘要，并定义我们如何计算ROUGE分数（请记住，Seq2SeqTrainer已经为我们处理了生成部分）。让我们来看看如何在🤗 Accelerate 中实现这两个要求！</p>
<h3 id="为训练做好一切准备"><a href="#为训练做好一切准备" class="headerlink" title="为训练做好一切准备"></a>为训练做好一切准备</h3><p>我们需要做的第一件事是为每个分割创建一个数据加载器。由于PyTorch数据加载器期望的是批次的张量，我们需要在我们的数据集中将格式设置为”torch”：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">tokenized_datasets<span class="token punctuation">.</span>set_format<span class="token punctuation">(</span><span class="token string">"torch"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>现在我们已经有了只包含张量的数据集，下一步就是再次实例化DataCollatorForSeq2Seq。为此，我们需要提供一个新的模型版本，所以让我们再次从缓存中加载它：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> AutoModelForSeq2SeqLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_checkpoint<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>然后，我们可以实例化数据收集器并使用它来定义我们的数据加载器：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader

batch_size <span class="token operator">=</span> <span class="token number">8</span>
train_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>
    tokenized_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    collate_fn<span class="token operator">=</span>data_collator<span class="token punctuation">,</span>
    batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>
<span class="token punctuation">)</span>
eval_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>
    tokenized_datasets<span class="token punctuation">[</span><span class="token string">"validation"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> collate_fn<span class="token operator">=</span>data_collator<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size
<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>接下来要做的是定义我们想要使用的优化器。和我们之前的例子一样，我们将使用AdamW，它对大多数问题都表现不错：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">import</span> AdamW

optimizer <span class="token operator">=</span> AdamW<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">2e-5</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>最后，我们将我们的模型、优化器和数据加载器传递给加速器的 prepare() 方法：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> accelerate <span class="token keyword">import</span> Accelerator

accelerator <span class="token operator">=</span> Accelerator<span class="token punctuation">(</span><span class="token punctuation">)</span>
model<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> train_dataloader<span class="token punctuation">,</span> eval_dataloader <span class="token operator">=</span> accelerator<span class="token punctuation">.</span>prepare<span class="token punctuation">(</span>
    model<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> train_dataloader<span class="token punctuation">,</span> eval_dataloader
<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>🚨 如果你在使用 TPU 进行训练，你需要将上面的所有代码移动到一个专门的训练函数中。更多细节请查看<a href="https://huggingface.co/course/chapter3">第 3 章</a>。</p>
</blockquote>
<p>现在我们已经准备好了所需的对象，接下来还有三件事情需要完成：</p>
<ol>
<li>定义学习率调度（schedule）。</li>
<li>实现一个函数，用于对摘要进行后处理，以便评估模型效果。</li>
<li>在 Hugging Face Hub 上创建一个仓库，以便我们可以将模型上传上去。</li>
</ol>
<p>对于学习率调度，我们将采用之前章节中使用的标准线性调度方式：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> get_scheduler

num_train_epochs <span class="token operator">=</span> <span class="token number">10</span>
num_update_steps_per_epoch <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span>
num_training_steps <span class="token operator">=</span> num_train_epochs <span class="token operator">*</span> num_update_steps_per_epoch

lr_scheduler <span class="token operator">=</span> get_scheduler<span class="token punctuation">(</span>
    <span class="token string">"linear"</span><span class="token punctuation">,</span>
    optimizer<span class="token operator">=</span>optimizer<span class="token punctuation">,</span>
    num_warmup_steps<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>
    num_training_steps<span class="token operator">=</span>num_training_steps<span class="token punctuation">,</span>
<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>对于后处理，我们需要一个函数，将生成的摘要分成由换行符分隔的句子。这是ROUGE指标所期望的格式，我们可以使用以下代码片段来实现：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">postprocess_text</span><span class="token punctuation">(</span>preds<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
    preds <span class="token operator">=</span> <span class="token punctuation">[</span>pred<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> pred <span class="token keyword">in</span> preds<span class="token punctuation">]</span>
    labels <span class="token operator">=</span> <span class="token punctuation">[</span>label<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> label <span class="token keyword">in</span> labels<span class="token punctuation">]</span>

    <span class="token comment"># ROUGE expects a newline after each sentence</span>
    preds <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"\n"</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>nltk<span class="token punctuation">.</span>sent_tokenize<span class="token punctuation">(</span>pred<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> pred <span class="token keyword">in</span> preds<span class="token punctuation">]</span>
    labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"\n"</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>nltk<span class="token punctuation">.</span>sent_tokenize<span class="token punctuation">(</span>label<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> label <span class="token keyword">in</span> labels<span class="token punctuation">]</span>

    <span class="token keyword">return</span> preds<span class="token punctuation">,</span> labels<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>如果你还记得我们是如何定义 Seq2SeqTrainer 的 compute_metrics() 函数的，那么这应该看起来很熟悉。</p>
<p>最后，我们需要在Hugging Face Hub上创建一个模型仓库。为此，我们可以使用名副其实的🤗 Hub库。我们只需要为我们的仓库定义一个名称，库中有一个实用函数可以将仓库ID与用户配置文件结合起来：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> huggingface_hub <span class="token keyword">import</span> get_full_repo_name

model_name <span class="token operator">=</span> <span class="token string">"test-bert-finetuned-squad-accelerate"</span>
repo_name <span class="token operator">=</span> get_full_repo_name<span class="token punctuation">(</span>model_name<span class="token punctuation">)</span>
repo_name<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token string">'lewtun/mt5-finetuned-amazon-en-es-accelerate'</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>现在我们可以使用这个仓库名称来克隆一个本地版本到我们的结果目录中，该目录将存储训练成果：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> huggingface_hub <span class="token keyword">import</span> Repository

output_dir <span class="token operator">=</span> <span class="token string">"results-mt5-finetuned-squad-accelerate"</span>
repo <span class="token operator">=</span> Repository<span class="token punctuation">(</span>output_dir<span class="token punctuation">,</span> clone_from<span class="token operator">=</span>repo_name<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<p>这将使我们能够在训练过程中通过调用 repo.push_to_hub() 方法将工件推送回 Hub！现在让我们通过编写训练循环来结束我们的分析。</p>
<h3 id="训练循环"><a href="#训练循环" class="headerlink" title="训练循环"></a>训练循环</h3><p>用于摘要任务的训练循环与我们之前遇到的其他 🤗 Accelerate 示例非常相似，大致可以分为四个主要步骤：</p>
<ol>
<li><strong>训练模型</strong>：在每个训练周期（epoch）中遍历 <code>train_dataloader</code> 中的所有样本，对模型进行训练。</li>
<li><strong>生成摘要</strong>：在每个 epoch 结束时生成模型的摘要结果。首先生成预测的 token，然后将这些 token（以及参考摘要）解码为文本形式。</li>
<li><strong>计算 ROUGE 分数</strong>：使用我们之前学到的技术来计算生成摘要与参考摘要之间的 ROUGE 指标，以评估模型性能。</li>
<li><strong>保存检查点并上传到 Hub</strong>：保存模型的检查点，并将所有内容推送到 Hugging Face Hub。这里我们巧妙地使用了 <code>Repository</code> 对象中的 <code>blocking=False</code> 参数，使得我们可以异步地按每个 epoch 上传检查点。这样即使上传一个大小为 GB 级别的模型时较慢，我们也可以继续进行下一轮的训练而不必等待上传完成！</li>
</ol>
<p>以下代码块中展示了这些步骤的具体实现：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> tqdm<span class="token punctuation">.</span>auto <span class="token keyword">import</span> tqdm
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

progress_bar <span class="token operator">=</span> tqdm<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>num_training_steps<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_train_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Training</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> step<span class="token punctuation">,</span> batch <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>batch<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> outputs<span class="token punctuation">.</span>loss
        accelerator<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>

        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        lr_scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        progress_bar<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token comment"># Evaluation</span>
    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> step<span class="token punctuation">,</span> batch <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>eval_dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            generated_tokens <span class="token operator">=</span> accelerator<span class="token punctuation">.</span>unwrap_model<span class="token punctuation">(</span>model<span class="token punctuation">)</span><span class="token punctuation">.</span>generate<span class="token punctuation">(</span>
                batch<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                attention_mask<span class="token operator">=</span>batch<span class="token punctuation">[</span><span class="token string">"attention_mask"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            <span class="token punctuation">)</span>

            generated_tokens <span class="token operator">=</span> accelerator<span class="token punctuation">.</span>pad_across_processes<span class="token punctuation">(</span>
                generated_tokens<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> pad_index<span class="token operator">=</span>tokenizer<span class="token punctuation">.</span>pad_token_id
            <span class="token punctuation">)</span>
            labels <span class="token operator">=</span> batch<span class="token punctuation">[</span><span class="token string">"labels"</span><span class="token punctuation">]</span>

            <span class="token comment"># If we did not pad to max length, we need to pad the labels too</span>
            labels <span class="token operator">=</span> accelerator<span class="token punctuation">.</span>pad_across_processes<span class="token punctuation">(</span>
                batch<span class="token punctuation">[</span><span class="token string">"labels"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> pad_index<span class="token operator">=</span>tokenizer<span class="token punctuation">.</span>pad_token_id
            <span class="token punctuation">)</span>

            generated_tokens <span class="token operator">=</span> accelerator<span class="token punctuation">.</span>gather<span class="token punctuation">(</span>generated_tokens<span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
            labels <span class="token operator">=</span> accelerator<span class="token punctuation">.</span>gather<span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># Replace -100 in the labels as we can't decode them</span>
            labels <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>labels <span class="token operator">!=</span> <span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">,</span> labels<span class="token punctuation">,</span> tokenizer<span class="token punctuation">.</span>pad_token_id<span class="token punctuation">)</span>
            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>generated_tokens<span class="token punctuation">,</span> <span class="token builtin">tuple</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                generated_tokens <span class="token operator">=</span> generated_tokens<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            decoded_preds <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>batch_decode<span class="token punctuation">(</span>
                generated_tokens<span class="token punctuation">,</span> skip_special_tokens<span class="token operator">=</span><span class="token boolean">True</span>
            <span class="token punctuation">)</span>
            decoded_labels <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>batch_decode<span class="token punctuation">(</span>labels<span class="token punctuation">,</span> skip_special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

            decoded_preds<span class="token punctuation">,</span> decoded_labels <span class="token operator">=</span> postprocess_text<span class="token punctuation">(</span>
                decoded_preds<span class="token punctuation">,</span> decoded_labels
            <span class="token punctuation">)</span>

            rouge_score<span class="token punctuation">.</span>add_batch<span class="token punctuation">(</span>predictions<span class="token operator">=</span>decoded_preds<span class="token punctuation">,</span> references<span class="token operator">=</span>decoded_labels<span class="token punctuation">)</span>

    <span class="token comment"># Compute metrics</span>
    result <span class="token operator">=</span> rouge_score<span class="token punctuation">.</span>compute<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># Extract the median ROUGE scores</span>
    result <span class="token operator">=</span> <span class="token punctuation">&#123;</span>key<span class="token punctuation">:</span> value<span class="token punctuation">.</span>mid<span class="token punctuation">.</span>fmeasure <span class="token operator">*</span> <span class="token number">100</span> <span class="token keyword">for</span> key<span class="token punctuation">,</span> value <span class="token keyword">in</span> result<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span>
    result <span class="token operator">=</span> <span class="token punctuation">&#123;</span>k<span class="token punctuation">:</span> <span class="token builtin">round</span><span class="token punctuation">(</span>v<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> result<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Epoch </span><span class="token interpolation"><span class="token punctuation">&#123;</span>epoch<span class="token punctuation">&#125;</span></span><span class="token string">:"</span></span><span class="token punctuation">,</span> result<span class="token punctuation">)</span>

    <span class="token comment"># Save and upload</span>
    accelerator<span class="token punctuation">.</span>wait_for_everyone<span class="token punctuation">(</span><span class="token punctuation">)</span>
    unwrapped_model <span class="token operator">=</span> accelerator<span class="token punctuation">.</span>unwrap_model<span class="token punctuation">(</span>model<span class="token punctuation">)</span>
    unwrapped_model<span class="token punctuation">.</span>save_pretrained<span class="token punctuation">(</span>output_dir<span class="token punctuation">,</span> save_function<span class="token operator">=</span>accelerator<span class="token punctuation">.</span>save<span class="token punctuation">)</span>
    <span class="token keyword">if</span> accelerator<span class="token punctuation">.</span>is_main_process<span class="token punctuation">:</span>
        tokenizer<span class="token punctuation">.</span>save_pretrained<span class="token punctuation">(</span>output_dir<span class="token punctuation">)</span>
        repo<span class="token punctuation">.</span>push_to_hub<span class="token punctuation">(</span>
            commit_message<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f"Training in progress epoch </span><span class="token interpolation"><span class="token punctuation">&#123;</span>epoch<span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">,</span> blocking<span class="token operator">=</span><span class="token boolean">False</span>
        <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">Epoch <span class="token number">0</span>: <span class="token punctuation">&#123;</span><span class="token string">'rouge1'</span><span class="token builtin class-name">:</span> <span class="token number">5.6351</span>, <span class="token string">'rouge2'</span><span class="token builtin class-name">:</span> <span class="token number">1.1625</span>, <span class="token string">'rougeL'</span><span class="token builtin class-name">:</span> <span class="token number">5.4866</span>, <span class="token string">'rougeLsum'</span><span class="token builtin class-name">:</span> <span class="token number">5.5005</span><span class="token punctuation">&#125;</span>
Epoch <span class="token number">1</span>: <span class="token punctuation">&#123;</span><span class="token string">'rouge1'</span><span class="token builtin class-name">:</span> <span class="token number">9.8646</span>, <span class="token string">'rouge2'</span><span class="token builtin class-name">:</span> <span class="token number">3.4106</span>, <span class="token string">'rougeL'</span><span class="token builtin class-name">:</span> <span class="token number">9.9439</span>, <span class="token string">'rougeLsum'</span><span class="token builtin class-name">:</span> <span class="token number">9.9306</span><span class="token punctuation">&#125;</span>
Epoch <span class="token number">2</span>: <span class="token punctuation">&#123;</span><span class="token string">'rouge1'</span><span class="token builtin class-name">:</span> <span class="token number">11.0872</span>, <span class="token string">'rouge2'</span><span class="token builtin class-name">:</span> <span class="token number">3.3273</span>, <span class="token string">'rougeL'</span><span class="token builtin class-name">:</span> <span class="token number">11.0508</span>, <span class="token string">'rougeLsum'</span><span class="token builtin class-name">:</span> <span class="token number">10.9468</span><span class="token punctuation">&#125;</span>
Epoch <span class="token number">3</span>: <span class="token punctuation">&#123;</span><span class="token string">'rouge1'</span><span class="token builtin class-name">:</span> <span class="token number">11.8587</span>, <span class="token string">'rouge2'</span><span class="token builtin class-name">:</span> <span class="token number">4.8167</span>, <span class="token string">'rougeL'</span><span class="token builtin class-name">:</span> <span class="token number">11.7986</span>, <span class="token string">'rougeLsum'</span><span class="token builtin class-name">:</span> <span class="token number">11.7518</span><span class="token punctuation">&#125;</span>
Epoch <span class="token number">4</span>: <span class="token punctuation">&#123;</span><span class="token string">'rouge1'</span><span class="token builtin class-name">:</span> <span class="token number">12.9842</span>, <span class="token string">'rouge2'</span><span class="token builtin class-name">:</span> <span class="token number">5.5887</span>, <span class="token string">'rougeL'</span><span class="token builtin class-name">:</span> <span class="token number">12.7546</span>, <span class="token string">'rougeLsum'</span><span class="token builtin class-name">:</span> <span class="token number">12.7029</span><span class="token punctuation">&#125;</span>
Epoch <span class="token number">5</span>: <span class="token punctuation">&#123;</span><span class="token string">'rouge1'</span><span class="token builtin class-name">:</span> <span class="token number">13.4628</span>, <span class="token string">'rouge2'</span><span class="token builtin class-name">:</span> <span class="token number">6.4598</span>, <span class="token string">'rougeL'</span><span class="token builtin class-name">:</span> <span class="token number">13.312</span>, <span class="token string">'rougeLsum'</span><span class="token builtin class-name">:</span> <span class="token number">13.2913</span><span class="token punctuation">&#125;</span>
Epoch <span class="token number">6</span>: <span class="token punctuation">&#123;</span><span class="token string">'rouge1'</span><span class="token builtin class-name">:</span> <span class="token number">12.9131</span>, <span class="token string">'rouge2'</span><span class="token builtin class-name">:</span> <span class="token number">5.8914</span>, <span class="token string">'rougeL'</span><span class="token builtin class-name">:</span> <span class="token number">12.6896</span>, <span class="token string">'rougeLsum'</span><span class="token builtin class-name">:</span> <span class="token number">12.5701</span><span class="token punctuation">&#125;</span>
Epoch <span class="token number">7</span>: <span class="token punctuation">&#123;</span><span class="token string">'rouge1'</span><span class="token builtin class-name">:</span> <span class="token number">13.3079</span>, <span class="token string">'rouge2'</span><span class="token builtin class-name">:</span> <span class="token number">6.2994</span>, <span class="token string">'rougeL'</span><span class="token builtin class-name">:</span> <span class="token number">13.1536</span>, <span class="token string">'rougeLsum'</span><span class="token builtin class-name">:</span> <span class="token number">13.1194</span><span class="token punctuation">&#125;</span>
Epoch <span class="token number">8</span>: <span class="token punctuation">&#123;</span><span class="token string">'rouge1'</span><span class="token builtin class-name">:</span> <span class="token number">13.96</span>, <span class="token string">'rouge2'</span><span class="token builtin class-name">:</span> <span class="token number">6.5998</span>, <span class="token string">'rougeL'</span><span class="token builtin class-name">:</span> <span class="token number">13.9123</span>, <span class="token string">'rougeLsum'</span><span class="token builtin class-name">:</span> <span class="token number">13.7744</span><span class="token punctuation">&#125;</span>
Epoch <span class="token number">9</span>: <span class="token punctuation">&#123;</span><span class="token string">'rouge1'</span><span class="token builtin class-name">:</span> <span class="token number">14.1192</span>, <span class="token string">'rouge2'</span><span class="token builtin class-name">:</span> <span class="token number">7.0059</span>, <span class="token string">'rougeL'</span><span class="token builtin class-name">:</span> <span class="token number">14.1172</span>, <span class="token string">'rougeLsum'</span><span class="token builtin class-name">:</span> <span class="token number">13.9509</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>就这样了！一旦你运行这个，你就会得到一个模型和结果，跟我们用Trainer得到的结果非常相似。</p>
<h2 id="使用您的微调模型"><a href="#使用您的微调模型" class="headerlink" title="使用您的微调模型"></a>使用您的微调模型</h2><p>一旦你将模型推送到 Hub，你可以通过推理小部件或管道对象来使用它，具体步骤如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline

hub_model_id <span class="token operator">=</span> <span class="token string">"huggingface-course/mt5-small-finetuned-amazon-en-es"</span>
summarizer <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">"summarization"</span><span class="token punctuation">,</span> model<span class="token operator">=</span>hub_model_id<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<p>我们可以将测试集（模型尚未见过的数据）的一些示例输入到我们的管道中，以了解摘要的质量。首先，让我们实现一个简单的函数，显示评论、标题和生成的摘要：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">print_summary</span><span class="token punctuation">(</span>idx<span class="token punctuation">)</span><span class="token punctuation">:</span>
    review <span class="token operator">=</span> books_dataset<span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"review_body"</span><span class="token punctuation">]</span>
    title <span class="token operator">=</span> books_dataset<span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"review_title"</span><span class="token punctuation">]</span>
    summary <span class="token operator">=</span> summarizer<span class="token punctuation">(</span>books_dataset<span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"review_body"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"summary_text"</span><span class="token punctuation">]</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"'>>> Review: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>review<span class="token punctuation">&#125;</span></span><span class="token string">'"</span></span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"\n'>>> Title: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>title<span class="token punctuation">&#125;</span></span><span class="token string">'"</span></span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"\n'>>> Summary: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>summary<span class="token punctuation">&#125;</span></span><span class="token string">'"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>让我们来看看我们收到的其中一个英语例子：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">print_summary<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token string">'>>> Review: Nothing special at all about this product... the book is too small and stiff and hard to write in. The huge sticker on the back doesn’t come off and looks super tacky. I would not purchase this again. I could have just bought a journal from the dollar store and it would be basically the same thing. It’s also really expensive for what it is.'</span>

<span class="token string">'>>> Title: Not impressed at all... buy something else'</span>

<span class="token string">'>>> Summary: Nothing special at all about this product'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>这还不错！我们可以看到，我们的模型通过用新词扩充评论的部分内容，实际上已经能够进行抽象式摘要了。也许我们模型最酷的方面是它是双语的，所以我们也可以生成西班牙语评论的摘要：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">print_summary<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token string">'>>> Review: Es una trilogia que se hace muy facil de leer. Me ha gustado, no me esperaba el final para nada'</span>

<span class="token string">'>>> Title: Buena literatura para adolescentes'</span>

<span class="token string">'>>> Summary: Muy facil de leer'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>总结在英语中翻译为“非常容易阅读”，我们可以看到在这个例子中是直接从评论中提取出来的。尽管如此，这展示了mT5模型的多功能性，让你体验了一下处理多语言语料库的感觉！</p>
<p>接下来，我们将把注意力转向一个稍微复杂一些的任务：从零开始训练一个语言模型。</p>
<h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>第三百三十二篇博文写完，开心！！！！</p>
<p>今天，也是充满希望的一天。</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">LuYF-Lemon-love</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://luyf-lemon-love.space/2025/05/03/00332-nlp-course-summarization/">https://luyf-lemon-love.space/2025/05/03/00332-nlp-course-summarization/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">LuYF-Lemon-love</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                                    <span class="chip bg-color">深度学习</span>
                                </a>
                            
                                <a href="/tags/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/">
                                    <span class="chip bg-color">大语言模型</span>
                                </a>
                            
                                <a href="/tags/huggingface/">
                                    <span class="chip bg-color">huggingface</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">谢谢小主！</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="https://cos.luyf-lemon-love.space/images/20220511162303.png" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="https://cos.luyf-lemon-love.space/images/20220511162220.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2025/05/05/00333-nlp-course-training-a-causal-language-model-from-scratch/">
                    <div class="card-image">
                        
                        <img src="https://cos.luyf-lemon-love.space/images/033-meinv.webp" class="responsive-img" alt="00333 NLP Course - Training a causal language model from scratch">
                        
                        <span class="card-title">00333 NLP Course - Training a causal language model from scratch</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-05
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" class="post-category">
                                    大语言模型
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">深度学习</span>
                    </a>
                    
                    <a href="/tags/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/">
                        <span class="chip bg-color">大语言模型</span>
                    </a>
                    
                    <a href="/tags/huggingface/">
                        <span class="chip bg-color">huggingface</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2025/05/03/00331-nlp-course-introduction/">
                    <div class="card-image">
                        
                        <img src="https://cos.luyf-lemon-love.space/images/031-meinv.webp" class="responsive-img" alt="00331 NLP Course - Introduction">
                        
                        <span class="card-title">00331 NLP Course - Introduction</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-03
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" class="post-category">
                                    大语言模型
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">深度学习</span>
                    </a>
                    
                    <a href="/tags/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/">
                        <span class="chip bg-color">大语言模型</span>
                    </a>
                    
                    <a href="/tags/huggingface/">
                        <span class="chip bg-color">huggingface</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>


  <!-- 是否加载使用自带的 prismjs. -->
  <script type="text/javascript" src="/libs/prism/prism.min.js"></script>


<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
    });
</script>



    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2022-2025</span>
            
            <a href="/about" target="_blank">LuYF-Lemon-love</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2022";
                        var startMonth = "5";
                        var startDate = "7";
                        var startHour = "4";
                        var startMinute = "53";
                        var startSecond = "32";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
                <span id="icp"><img src="/medias/icp.png"
                                    style="vertical-align: text-bottom;"/>
                <a href="https://beian.miit.gov.cn" target="_blank">冀ICP备2022012632号-1</a>
            </span>
            
            <br>
            
                <span id="gongan"><img src="https://cos.luyf-lemon-love.space/images/备案图标.png"
                                    style="vertical-align: text-bottom;"/>
                <a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=32011502011618" target="_blank">苏公网安备 32011502011618号</a>
            </span>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/yanfeng98" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:luyanfeng_nlp@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>













    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
    
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
     
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/libs/others/star.js"><\/script>');
            }
        </script>
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    
    <script type="text/javascript" color="0,0,255"
        pointColor="0,0,255" opacity='0.7'
        zIndex="-1" count="99"
        src="/libs/background/canvas-nest.js"></script>
    

    

    
    <script type="text/javascript" src="/libs/background/ribbon-dynamic.js" async="async"></script>
    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
